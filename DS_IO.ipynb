{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "%logstop\n",
    "%logstart -rtq ~/.logs/DS_IO.py append\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "matplotlib.rcParams['figure.dpi'] = 144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import expectexception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing and Exporting Data\n",
    "\n",
    "<!-- requirement: data/sample.txt -->\n",
    "<!-- requirement: data/csv_sample.txt -->\n",
    "<!-- requirement: data/bad_csv.csv -->\n",
    "\n",
    "So far we've only dealt with data that we have created within Python. Generating random data is helpful for testing out ideas, but we want to work with real data. Most often that data will be stored in a file, either locally on the computer or online. In this notebook we'll learn how to read and write data to files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python file handles (`open`)\n",
    "\n",
    "In Python we interact with files on disk using the commands `open` and `close`. We've included a file in the `data` folder called `sample.txt`. Let's open it and read its contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello!\n",
      "Congratulations!\n",
      "You've read in data from a file.\n",
      "<_io.TextIOWrapper name='./data/sample.txt' mode='r' encoding='UTF-8'>\n"
     ]
    }
   ],
   "source": [
    "f = open('./data/sample.txt', 'r')\n",
    "data = f.read()\n",
    "f.close()\n",
    "\n",
    "print(data)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we `open` the file  and assign it to `f`, `read` the data from `f`, and then close `f`. What is `f`? It's called a **file handle**. It's an object that connects Python to the file we `open`. We `read` the data using this connection, and then once we're done with `close` the connection. It's a good habit to `close` a file handle once we're done with it, so usually we will do it automatically using Python's `with` keyword. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello!\n",
      "Congratulations!\n",
      "You've read in data from a file.\n",
      "<_io.TextIOWrapper name='./data/sample.txt' mode='r' encoding='UTF-8'>\n"
     ]
    }
   ],
   "source": [
    "# f is automatically closed\n",
    "# at the end of the body of the with statement\n",
    "with open('./data/sample.txt', 'r') as f:\n",
    "    print(f.read())\n",
    "\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also read individual lines of a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello!\n",
      "\n",
      "Congratulations!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('./data/sample.txt', 'r') as f:\n",
    "    print(f.readline())\n",
    "    print(f.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello!\\n', 'Congratulations!\\n', \"You've read in data from a file.\"]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "with open('./data/sample.txt', 'r') as f:\n",
    "    print(f.readlines())\n",
    "    print(f.readlines())\n",
    "    print(f.readlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing data to files is very similar. The main difference is when we `open` the file, we will use the `'w'` flag instead of `'r'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a new file.\n",
      "I am practicing writing data to disk.\n"
     ]
    }
   ],
   "source": [
    "with open('./data/my_data.txt', 'w') as f:\n",
    "    f.write('This is a new file.\\n')\n",
    "    f.write('I am practicing writing data to disk.')\n",
    "\n",
    "with open('./data/my_data.txt', 'r') as f:\n",
    "    my_data = f.read()\n",
    "\n",
    "print(my_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No matter how often I execute the above cell, the same output gets printed. Opening the file with the `'w'` flag will overwrite the contents of the file. If we want to add to what is already in the file, we have to open the file with the `'a'` flag (`'a'` stands for _append_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a new file.\n",
      "I am practicing writing data to disk.\n",
      "Adding a new line to the file.\n"
     ]
    }
   ],
   "source": [
    "with open('./data/my_data.txt', 'a') as f:\n",
    "    f.write('\\nAdding a new line to the file.')\n",
    "\n",
    "with open('./data/my_data.txt', 'r') as f:\n",
    "    my_data = f.read()\n",
    "\n",
    "print(my_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We always need to be careful when writing to disk, because we could overwrite or alter data by accident. It is also easy to encounter errors when working with files, because we might not know ahead of time if the file we're trying to access exists, or we might mix up the `'r'`, `'w'`, and `'a'` flags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ExceptionExpected",
     "evalue": "This cell did not raise the expected IOError.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mExceptionExpected\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-a2eda2783467>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'expect_exception'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'IOError'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n# if a file doesn't exist\\n# we can't open it for reading\\n# (but we can open it for writing)\\n\\nwith open('./data/fail.txt', 'r') as f:\\n    f.read()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2165\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2166\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2167\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2168\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</opt/conda/lib/python3.7/site-packages/decorator.py:decorator-gen-125>\u001b[0m in \u001b[0;36mexpect_exception\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/expectexception/excpectexceptionmagic.py\u001b[0m in \u001b[0;36mexpect_exception\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcell_magic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexpect_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcell_magic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/expectexception/excpectexceptionmagic.py\u001b[0m in \u001b[0;36mrun_cell\u001b[0;34m(self, line, cell, exception_required)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mexception_required\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_in_exec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mExceptionExpected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"This cell did not raise the expected %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCustomTB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_CustomTB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mExceptionExpected\u001b[0m: This cell did not raise the expected IOError."
     ]
    }
   ],
   "source": [
    "%%expect_exception IOError\n",
    "\n",
    "# if a file doesn't exist\n",
    "# we can't open it for reading\n",
    "# (but we can open it for writing)\n",
    "\n",
    "with open('./data/fail.txt', 'r') as f:\n",
    "    f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mUnsupportedOperation\u001b[0m                      Traceback (most recent call last)\n",
      "\u001b[0;32m<ipython-input-23-2396ab194fe8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/fail.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0;31mUnsupportedOperation\u001b[0m: not readable\n"
     ]
    }
   ],
   "source": [
    "%%expect_exception IOError\n",
    "\n",
    "# we can't read a file open for writing\n",
    "\n",
    "with open('./data/fail.txt', 'w') as f:\n",
    "    f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mUnsupportedOperation\u001b[0m                      Traceback (most recent call last)\n",
      "\u001b[0;32m<ipython-input-24-415e83617ea3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/sample.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'This will fail'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0;31mUnsupportedOperation\u001b[0m: not writable\n"
     ]
    }
   ],
   "source": [
    "%%expect_exception IOError\n",
    "\n",
    "# and we can't write to a file open for reading\n",
    "\n",
    "with open('./data/sample.txt', 'r') as f:\n",
    "    f.write('This will fail')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we prevent some of these errors? How do we find out what files are on disk?\n",
    "\n",
    "## `os` module\n",
    "\n",
    "Python has a module for navigating the computer's file system called `os`. There are many useful tools in the `os` module, but there are two functions that are most useful for finding files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DS_SQL.ipynb',\n",
       " 'DS_Pandas.ipynb',\n",
       " 'DS_IO.ipynb',\n",
       " 'data',\n",
       " 'miniprojects',\n",
       " 'DS_Intro_Statistics.ipynb',\n",
       " '.ipynb_checkpoints',\n",
       " 'DS_Classes_and_ORM.ipynb',\n",
       " '.done',\n",
       " 'DS_Basic_DS_Modules.ipynb',\n",
       " 'DS_Data_Munging.ipynb']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# list the contents of the current directory\n",
    "# ('.' refers to the current directory)\n",
    "os.listdir('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command `listdir` is the simpler of the two functions we'll cover. It simply lists the contents of the directory path we specify. When we pass `'.'` as the argument, `listdir` will look in the current directory. It lists all the Jupyter notebooks we're using for the course, as well as the `data` subdirectory. We could find out what's in the `data` subdirectory by looking in `'./data'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['csv_sample.txt',\n",
       " 'bad_csv.csv',\n",
       " 'orders.csv',\n",
       " 'my_data.txt',\n",
       " 'products.csv',\n",
       " 'yelp.json.gz',\n",
       " 'fail.txt',\n",
       " 'customers.csv',\n",
       " 'PEP_2016_PEPANNRES.csv',\n",
       " 'sample.txt']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we wanted to find all the files and subdirectories below a directory somewhere on our computer? With `listdir` we only see the files and subdirectories under the particular directory we're looking in. We cannot use `listdir` to automatically search through subdirectories. For this we need to use `walk`, which \"walks\" through all the subdirectories below our chosen directory. We won't cover `walk` in this course, but it's one of the very useful tools (along with the `os.path` sub-module) for working with files in Python, particularly if you are working with many different data files at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for directory, _, filenames in os.walk('/home/user/mali134/tree/datacourse'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(directory, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV files\n",
    "\n",
    "One of the simplest and most common formats for saving data is as comma-separated values (CSV)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index,name,age\n",
      "0,Dylan,28\n",
      "1,Terrence,54\n",
      "2,Mya,31\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('./data/csv_sample.txt', 'r') as f:\n",
    "    csv = f.read()\n",
    "\n",
    "print(csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This format is often used to represent tables of data. Usually a CSV will have rows (separated by newline characters, `'\\n'`) and columns (separated by commas). Otherwise they are no different from any other text file. We can use the special formatting of a CSV to create a list of lists representing the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['index', 'name', 'age'],\n",
       " ['0', 'Dylan', '28'],\n",
       " ['1', 'Terrence', '54'],\n",
       " ['2', 'Mya', '31']]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_table = []\n",
    "with open('./data/csv_sample.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        list_table.append(line.strip().split(','))\n",
    "\n",
    "list_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we can work with tabular data much more easily in a Pandas DataFrame. Pandas provides a `read_csv` method to read the data directly into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dylan</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Terrence</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mya</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name  age\n",
       "index               \n",
       "0         Dylan   28\n",
       "1      Terrence   54\n",
       "2           Mya   31"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./data/csv_sample.txt', index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `read_csv` method is very flexible to deal with the formatting of different data sets. Some data sets will include column headers while others may not. Some data sets will include an index while others may not. Some data sets may have values separated by tabs, semicolons, or other characters instead of commas. There are options in the `read_csv` method for dealing with all of these. You can read about them in the [Pandas documentation on `read_csv`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html). We'll also discuss it further in the [Pandas notebook](DS_Pandas.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-04-28 07:27:22--  https://perso.telecom-paristech.fr/eagan/class/igr204/data/factbook.csv\n",
      "Resolving perso.telecom-paristech.fr (perso.telecom-paristech.fr)... 137.194.2.165, 2001:660:330f:2::a5\n",
      "Connecting to perso.telecom-paristech.fr (perso.telecom-paristech.fr)|137.194.2.165|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 64856 (63K) [text/csv]\n",
      "Saving to: ‘./data/factbook.csv’\n",
      "\n",
      "factbook.csv        100%[===================>]  63.34K  --.-KB/s    in 0.08s   \n",
      "\n",
      "2020-04-28 07:27:22 (767 KB/s) - ‘./data/factbook.csv’ saved [64856/64856]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Area(sq km)</th>\n",
       "      <th>Birth rate(births/1000 population)</th>\n",
       "      <th>Current account balance</th>\n",
       "      <th>Death rate(deaths/1000 population)</th>\n",
       "      <th>Debt - external</th>\n",
       "      <th>Electricity - consumption(kWh)</th>\n",
       "      <th>Electricity - production(kWh)</th>\n",
       "      <th>Exports</th>\n",
       "      <th>GDP</th>\n",
       "      <th>...</th>\n",
       "      <th>Oil - production(bbl/day)</th>\n",
       "      <th>Oil - proved reserves(bbl)</th>\n",
       "      <th>Population</th>\n",
       "      <th>Public debt(% of GDP)</th>\n",
       "      <th>Railways(km)</th>\n",
       "      <th>Reserves of foreign exchange &amp; gold</th>\n",
       "      <th>Telephones - main lines in use</th>\n",
       "      <th>Telephones - mobile cellular</th>\n",
       "      <th>Total fertility rate(children born/woman)</th>\n",
       "      <th>Unemployment rate(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>647500</td>\n",
       "      <td>47.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.75</td>\n",
       "      <td>8.000000e+09</td>\n",
       "      <td>6.522000e+08</td>\n",
       "      <td>5.400000e+08</td>\n",
       "      <td>4.460000e+08</td>\n",
       "      <td>2.150000e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>29928987.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33100.0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>6.75</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Akrotiri</td>\n",
       "      <td>123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albania</td>\n",
       "      <td>28748</td>\n",
       "      <td>15.08</td>\n",
       "      <td>-5.040000e+08</td>\n",
       "      <td>5.12</td>\n",
       "      <td>1.410000e+09</td>\n",
       "      <td>6.760000e+09</td>\n",
       "      <td>5.680000e+09</td>\n",
       "      <td>5.524000e+08</td>\n",
       "      <td>1.746000e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1.855000e+08</td>\n",
       "      <td>3563112.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>447.0</td>\n",
       "      <td>1.206000e+09</td>\n",
       "      <td>255000.0</td>\n",
       "      <td>1100000.0</td>\n",
       "      <td>2.04</td>\n",
       "      <td>14.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>2381740</td>\n",
       "      <td>17.13</td>\n",
       "      <td>1.190000e+10</td>\n",
       "      <td>4.60</td>\n",
       "      <td>2.190000e+10</td>\n",
       "      <td>2.361000e+10</td>\n",
       "      <td>2.576000e+10</td>\n",
       "      <td>3.216000e+10</td>\n",
       "      <td>2.123000e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>1.187000e+10</td>\n",
       "      <td>32531853.0</td>\n",
       "      <td>37.4</td>\n",
       "      <td>3973.0</td>\n",
       "      <td>4.355000e+10</td>\n",
       "      <td>2199600.0</td>\n",
       "      <td>1447310.0</td>\n",
       "      <td>1.92</td>\n",
       "      <td>25.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>American Samoa</td>\n",
       "      <td>199</td>\n",
       "      <td>23.13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.209000e+08</td>\n",
       "      <td>1.300000e+08</td>\n",
       "      <td>3.000000e+07</td>\n",
       "      <td>5.000000e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57881.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>2377.0</td>\n",
       "      <td>3.25</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Country  Area(sq km)  Birth rate(births/1000 population)  \\\n",
       "0     Afghanistan       647500                               47.02   \n",
       "1        Akrotiri          123                                 NaN   \n",
       "2         Albania        28748                               15.08   \n",
       "3         Algeria      2381740                               17.13   \n",
       "4  American Samoa          199                               23.13   \n",
       "\n",
       "   Current account balance  Death rate(deaths/1000 population)  \\\n",
       "0                      NaN                               20.75   \n",
       "1                      NaN                                 NaN   \n",
       "2            -5.040000e+08                                5.12   \n",
       "3             1.190000e+10                                4.60   \n",
       "4                      NaN                                3.33   \n",
       "\n",
       "   Debt - external  Electricity - consumption(kWh)  \\\n",
       "0     8.000000e+09                    6.522000e+08   \n",
       "1              NaN                             NaN   \n",
       "2     1.410000e+09                    6.760000e+09   \n",
       "3     2.190000e+10                    2.361000e+10   \n",
       "4              NaN                    1.209000e+08   \n",
       "\n",
       "   Electricity - production(kWh)       Exports           GDP  ...  \\\n",
       "0                   5.400000e+08  4.460000e+08  2.150000e+10  ...   \n",
       "1                            NaN           NaN           NaN  ...   \n",
       "2                   5.680000e+09  5.524000e+08  1.746000e+10  ...   \n",
       "3                   2.576000e+10  3.216000e+10  2.123000e+11  ...   \n",
       "4                   1.300000e+08  3.000000e+07  5.000000e+08  ...   \n",
       "\n",
       "   Oil - production(bbl/day)  Oil - proved reserves(bbl)  Population  \\\n",
       "0                        0.0                0.000000e+00  29928987.0   \n",
       "1                        NaN                         NaN         NaN   \n",
       "2                     2000.0                1.855000e+08   3563112.0   \n",
       "3                  1200000.0                1.187000e+10  32531853.0   \n",
       "4                        0.0                         NaN     57881.0   \n",
       "\n",
       "   Public debt(% of GDP)  Railways(km)  Reserves of foreign exchange & gold  \\\n",
       "0                    NaN           NaN                                  NaN   \n",
       "1                    NaN           NaN                                  NaN   \n",
       "2                    NaN         447.0                         1.206000e+09   \n",
       "3                   37.4        3973.0                         4.355000e+10   \n",
       "4                    NaN           NaN                                  NaN   \n",
       "\n",
       "   Telephones - main lines in use  Telephones - mobile cellular  \\\n",
       "0                         33100.0                       15000.0   \n",
       "1                             NaN                           NaN   \n",
       "2                        255000.0                     1100000.0   \n",
       "3                       2199600.0                     1447310.0   \n",
       "4                         15000.0                        2377.0   \n",
       "\n",
       "   Total fertility rate(children born/woman)  Unemployment rate(%)  \n",
       "0                                       6.75                   NaN  \n",
       "1                                        NaN                   NaN  \n",
       "2                                       2.04                  14.8  \n",
       "3                                       1.92                  25.4  \n",
       "4                                       3.25                   6.0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# an example of downloading\n",
    "# and importing real data using `read_csv`\n",
    "\n",
    "if 'factbook.csv' not in os.listdir('./data/'):\n",
    "    !wget -P ./data/ https://perso.telecom-paristech.fr/eagan/class/igr204/data/factbook.csv\n",
    "\n",
    "countries = pd.read_csv('./data/factbook.csv', delimiter=';', skiprows=[1])\n",
    "countries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also use pandas to write CSV\n",
    "# using the DataFrame's to_csv method\n",
    "\n",
    "pd.DataFrame({'a': [0, 3, 10], 'b': [True, True, False]}).to_csv('./data/pd_write.csv')\n",
    "\n",
    "pd.read_csv('./data/pd_write.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes a CSV won't be perfect. For example, maybe different rows have different numbers of commas. This makes it difficult to interpret the contents of the file as a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the 3rd line only has 2 \"columns\"\n",
    "\n",
    "!cat ./data/bad_csv.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what happens if we try to read this\n",
    "# into a DataFrame using read_csv?\n",
    "\n",
    "pd.read_csv('./data/bad_csv.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas' `read_csv` method will do its best to construct a table out of a poorly formatted CSV, but it may make mistakes. For example, 54 was interpreted as a name instead of as an age, because there were only 2 columns in that line of the file. Data sets will often contain mistakes like bad formatting, missing data, or typos.\n",
    "\n",
    "**Question:** How could we fix the badly formatted CSV so it would work with `read_csv`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON\n",
    "\n",
    "JSON stands for JavaScript Object Notation. JavaScript is a common language for creating web applications, and JSON files are used to collect and transmit information between JavaScript applications. As a result, a lot of data on the internet exists in the JSON file format. For example, Twitter and Google Maps use JSON.\n",
    "\n",
    "A JSON file is essentially a data structure built out of nested dictionaries and lists. Let's make our own example and then we'll examine an example downloaded from the internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'The Prophet',\n",
       "  'author': 'Khalil Gibran',\n",
       "  'genre': 'poetry',\n",
       "  'tags': ['religion',\n",
       "   'spirituality',\n",
       "   'philosophy',\n",
       "   'Lebanon',\n",
       "   'Arabic',\n",
       "   'Middle East'],\n",
       "  'book_id': '811.19',\n",
       "  'copies': [{'edition_year': 1996, 'checkouts': 486, 'borrowed': False},\n",
       "   {'edition_year': 1996, 'checkouts': 443, 'borrowed': False}]},\n",
       " {'title': 'The Little Prince',\n",
       "  'author': 'Antoine de Saint-Exupery',\n",
       "  'genre': 'children',\n",
       "  'tags': ['fantasy', 'France', 'philosophy', 'illustrated', 'fable'],\n",
       "  'id': '843.912',\n",
       "  'copies': [{'edition_year': 1983,\n",
       "    'checkouts': 634,\n",
       "    'borrowed': True,\n",
       "    'due_date': '2017/02/02'},\n",
       "   {'edition_year': 2015, 'checkouts': 41, 'borrowed': False}]}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book1 = {'title': 'The Prophet',\n",
    "         'author': 'Khalil Gibran',\n",
    "         'genre': 'poetry',\n",
    "         'tags': ['religion', 'spirituality', 'philosophy', 'Lebanon', 'Arabic', 'Middle East'],\n",
    "         'book_id': '811.19',\n",
    "         'copies': [{'edition_year': 1996,\n",
    "                     'checkouts': 486,\n",
    "                     'borrowed': False},\n",
    "                    {'edition_year': 1996,\n",
    "                     'checkouts': 443,\n",
    "                     'borrowed': False}]\n",
    "         }\n",
    "         \n",
    "book2 = {'title': 'The Little Prince',\n",
    "         'author': 'Antoine de Saint-Exupery',\n",
    "         'genre': 'children',\n",
    "         'tags': ['fantasy', 'France', 'philosophy', 'illustrated', 'fable'],\n",
    "         'id': '843.912',\n",
    "         'copies': [{'edition_year': 1983,\n",
    "                     'checkouts': 634,\n",
    "                     'borrowed': True,\n",
    "                     'due_date': '2017/02/02'},\n",
    "                    {'edition_year': 2015,\n",
    "                     'checkouts': 41,\n",
    "                     'borrowed': False}]\n",
    "         }\n",
    "\n",
    "library = [book1, book2]\n",
    "library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two books in our `library`. Both books have some common properties: a title, an author, an id, and tags. Each book can have several tags, so we store that data as a list. Additionally, there can be multiple copies of each book, and each copy also has some unique information like the year it was printed and how many times it's been checked out. Notice that if a book is checked out, it also has a due date. It's convenient to store the information about the multiple copies as a list of dictionaries within the dictionary about the book, because every copy shares the same title, author, etc.\n",
    "\n",
    "This structure is typical of JSON files. It has the advantage of reducing redundancy of data. We only store the author and title once, even though there are multiple copies of the book. Also, we don't store a due date for copies that aren't checked out.\n",
    "\n",
    "If we were to put this data in a table, we would have to duplicate a lot of information. Also, since only one copy in our library is checked out, we also have a column with a lot of missing data.\n",
    "\n",
    "|index|title|author|id|genre|tags|edition_year|checkouts|borrowed|due_date|\n",
    "|:---:|:---:|:----:|::|:---:|:--:|:----------:|:-------:|:------:|:------:|\n",
    "|0|The Prophet|Khalil Gibran|811.19|poetry|religion, spirituality, philosophy, Lebanon, Arabic, Middle East|1996|486|False|Null|\n",
    "|1|The Prophet|Khalil Gibran|811.19|poetry|religion, spirituality, philosophy, Lebanon, Arabic, Middle East|1996|443|False|Null|\n",
    "|2|The Little Prince|Antoine de Saint-Exupery|843.912|children|fantasy, France, philosophy, illustrated, fable|1983|634|True|2017/02/02|\n",
    "|3|The Little Prince|Antoine de Saint-Exupery|843.912|children|fantasy, France, philosophy, illustrated, fable|2015|41|False|Null|\n",
    "\n",
    "This is very wasteful. Since JSON files are meant to be shared quickly over the internet, it is important that they are small to reduce the amount of resources needed to store and transmit them.\n",
    "\n",
    "We can write our `library` to disk using the `json` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('./data/library.json', 'w') as f:\n",
    "    json.dump(library, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\r\n",
      "  {\r\n",
      "    \"title\": \"The Prophet\",\r\n",
      "    \"author\": \"Khalil Gibran\",\r\n",
      "    \"genre\": \"poetry\",\r\n",
      "    \"tags\": [\r\n",
      "      \"religion\",\r\n",
      "      \"spirituality\",\r\n",
      "      \"philosophy\",\r\n",
      "      \"Lebanon\",\r\n",
      "      \"Arabic\",\r\n",
      "      \"Middle East\"\r\n",
      "    ],\r\n",
      "    \"book_id\": \"811.19\",\r\n",
      "    \"copies\": [\r\n",
      "      {\r\n",
      "        \"edition_year\": 1996,\r\n",
      "        \"checkouts\": 486,\r\n",
      "        \"borrowed\": false\r\n",
      "      },\r\n",
      "      {\r\n",
      "        \"edition_year\": 1996,\r\n",
      "        \"checkouts\": 443,\r\n",
      "        \"borrowed\": false\r\n",
      "      }\r\n",
      "    ]\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"title\": \"The Little Prince\",\r\n",
      "    \"author\": \"Antoine de Saint-Exupery\",\r\n",
      "    \"genre\": \"children\",\r\n",
      "    \"tags\": [\r\n",
      "      \"fantasy\",\r\n",
      "      \"France\",\r\n",
      "      \"philosophy\",\r\n",
      "      \"illustrated\",\r\n",
      "      \"fable\"\r\n",
      "    ],\r\n",
      "    \"id\": \"843.912\",\r\n",
      "    \"copies\": [\r\n",
      "      {\r\n",
      "        \"edition_year\": 1983,\r\n",
      "        \"checkouts\": 634,\r\n",
      "        \"borrowed\": true,\r\n",
      "        \"due_date\": \"2017/02/02\"\r\n",
      "      },\r\n",
      "      {\r\n",
      "        \"edition_year\": 2015,\r\n",
      "        \"checkouts\": 41,\r\n",
      "        \"borrowed\": false\r\n",
      "      }\r\n",
      "    ]\r\n",
      "  }\r\n",
      "]"
     ]
    }
   ],
   "source": [
    "!cat ./data/library.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'The Prophet',\n",
       "  'author': 'Khalil Gibran',\n",
       "  'genre': 'poetry',\n",
       "  'tags': ['religion',\n",
       "   'spirituality',\n",
       "   'philosophy',\n",
       "   'Lebanon',\n",
       "   'Arabic',\n",
       "   'Middle East'],\n",
       "  'book_id': '811.19',\n",
       "  'copies': [{'edition_year': 1996, 'checkouts': 486, 'borrowed': False},\n",
       "   {'edition_year': 1996, 'checkouts': 443, 'borrowed': False}]},\n",
       " {'title': 'The Little Prince',\n",
       "  'author': 'Antoine de Saint-Exupery',\n",
       "  'genre': 'children',\n",
       "  'tags': ['fantasy', 'France', 'philosophy', 'illustrated', 'fable'],\n",
       "  'id': '843.912',\n",
       "  'copies': [{'edition_year': 1983,\n",
       "    'checkouts': 634,\n",
       "    'borrowed': True,\n",
       "    'due_date': '2017/02/02'},\n",
       "   {'edition_year': 2015, 'checkouts': 41, 'borrowed': False}]}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./data/library.json', 'r') as f:\n",
    "    reloaded_library = json.load(f)\n",
    "\n",
    "reloaded_library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\\n  {\\n    \"title\": \"The Prophet\",\\n    \"author\": \"Khalil Gibran\",\\n    \"genre\": \"poetry\",\\n    \"tags\": [\\n      \"religion\",\\n      \"spirituality\",\\n      \"philosophy\",\\n      \"Lebanon\",\\n      \"Arabic\",\\n      \"Middle East\"\\n    ],\\n    \"book_id\": \"811.19\",\\n    \"copies\": [\\n      {\\n        \"edition_year\": 1996,\\n        \"checkouts\": 486,\\n        \"borrowed\": false\\n      },\\n      {\\n        \"edition_year\": 1996,\\n        \"checkouts\": 443,\\n        \"borrowed\": false\\n      }\\n    ]\\n  },\\n  {\\n    \"title\": \"The Little Prince\",\\n    \"author\": \"Antoine de Saint-Exupery\",\\n    \"genre\": \"children\",\\n    \"tags\": [\\n      \"fantasy\",\\n      \"France\",\\n      \"philosophy\",\\n      \"illustrated\",\\n      \"fable\"\\n    ],\\n    \"id\": \"843.912\",\\n    \"copies\": [\\n      {\\n        \"edition_year\": 1983,\\n        \"checkouts\": 634,\\n        \"borrowed\": true,\\n        \"due_date\": \"2017/02/02\"\\n      },\\n      {\\n        \"edition_year\": 2015,\\n        \"checkouts\": 41,\\n        \"borrowed\": false\\n      }\\n    ]\\n  }\\n]'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note that if we loaded it in without JSON\n",
    "# the file would be interpreted as plain text\n",
    "\n",
    "with open('./data/library.json', 'r') as f:\n",
    "    library_string = f.read()\n",
    "\n",
    "# this isn't what we want\n",
    "library_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'The Prophet',\n",
       "  'author': 'Khalil Gibran',\n",
       "  'genre': 'poetry',\n",
       "  'tags': ['religion',\n",
       "   'spirituality',\n",
       "   'philosophy',\n",
       "   'Lebanon',\n",
       "   'Arabic',\n",
       "   'Middle East'],\n",
       "  'book_id': '811.19',\n",
       "  'copies': [{'edition_year': 1996, 'checkouts': 486, 'borrowed': False},\n",
       "   {'edition_year': 1996, 'checkouts': 443, 'borrowed': False}]},\n",
       " {'title': 'The Little Prince',\n",
       "  'author': 'Antoine de Saint-Exupery',\n",
       "  'genre': 'children',\n",
       "  'tags': ['fantasy', 'France', 'philosophy', 'illustrated', 'fable'],\n",
       "  'id': '843.912',\n",
       "  'copies': [{'edition_year': 1983,\n",
       "    'checkouts': 634,\n",
       "    'borrowed': True,\n",
       "    'due_date': '2017/02/02'},\n",
       "   {'edition_year': 2015, 'checkouts': 41, 'borrowed': False}]}]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(library_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>genre</th>\n",
       "      <th>tags</th>\n",
       "      <th>book_id</th>\n",
       "      <th>copies</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Prophet</td>\n",
       "      <td>Khalil Gibran</td>\n",
       "      <td>poetry</td>\n",
       "      <td>[religion, spirituality, philosophy, Lebanon, ...</td>\n",
       "      <td>811.19</td>\n",
       "      <td>[{'edition_year': 1996, 'checkouts': 486, 'bor...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Little Prince</td>\n",
       "      <td>Antoine de Saint-Exupery</td>\n",
       "      <td>children</td>\n",
       "      <td>[fantasy, France, philosophy, illustrated, fable]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'edition_year': 1983, 'checkouts': 634, 'bor...</td>\n",
       "      <td>843.912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               title                    author     genre  \\\n",
       "0        The Prophet             Khalil Gibran    poetry   \n",
       "1  The Little Prince  Antoine de Saint-Exupery  children   \n",
       "\n",
       "                                                tags  book_id  \\\n",
       "0  [religion, spirituality, philosophy, Lebanon, ...   811.19   \n",
       "1  [fantasy, France, philosophy, illustrated, fable]      NaN   \n",
       "\n",
       "                                              copies       id  \n",
       "0  [{'edition_year': 1996, 'checkouts': 486, 'bor...      NaN  \n",
       "1  [{'edition_year': 1983, 'checkouts': 634, 'bor...  843.912  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pandas can also read_json\n",
    "# notice how it constructs the table\n",
    "# does it represent the data well?\n",
    "\n",
    "pd.read_json('./data/library.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\":{\"0\":\"Dylan\",\"1\":\"Terrence\",\"2\":\"Mya\"},\"age\":{\"0\":28,\"1\":54,\"2\":31}}"
     ]
    }
   ],
   "source": [
    "# and to_json\n",
    "df.to_json('./data/example_df.json')\n",
    "\n",
    "!head ./data/example_df.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can download JSON files many ways. Sometimes we will download it manually, but we can also use `wget` like we did for the CSV example. Often we'll connect to a website's API which will respond using JSON.\n",
    "\n",
    "Panda's `read_json` method is capable of connecting directly to a URL (whether it's the address of a JSON file or an API connection) and reading the JSON without saving the file to our computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>repository_url</th>\n",
       "      <th>labels_url</th>\n",
       "      <th>comments_url</th>\n",
       "      <th>events_url</th>\n",
       "      <th>html_url</th>\n",
       "      <th>id</th>\n",
       "      <th>node_id</th>\n",
       "      <th>number</th>\n",
       "      <th>title</th>\n",
       "      <th>...</th>\n",
       "      <th>assignee</th>\n",
       "      <th>assignees</th>\n",
       "      <th>milestone</th>\n",
       "      <th>comments</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>closed_at</th>\n",
       "      <th>author_association</th>\n",
       "      <th>body</th>\n",
       "      <th>pull_request</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://github.com/pandas-dev/pandas/issues/33841</td>\n",
       "      <td>608107436</td>\n",
       "      <td>MDU6SXNzdWU2MDgxMDc0MzY=</td>\n",
       "      <td>33841</td>\n",
       "      <td>BUG:RecursionError occur when running the scri...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-04-28 07:59:09+00:00</td>\n",
       "      <td>2020-04-28 08:11:12+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>This is my first issue. So, if I'm wrong, plea...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://github.com/pandas-dev/pandas/pull/33840</td>\n",
       "      <td>608057209</td>\n",
       "      <td>MDExOlB1bGxSZXF1ZXN0NDA5OTA4NjMy</td>\n",
       "      <td>33840</td>\n",
       "      <td>DOC: Fix groupby.agg/transform API reference a...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'url': 'https://api.github.com/repos/pandas-d...</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-04-28 06:22:51+00:00</td>\n",
       "      <td>2020-04-28 06:25:59+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>MEMBER</td>\n",
       "      <td>- xref https://github.com/pandas-dev/pandas/pu...</td>\n",
       "      <td>{'url': 'https://api.github.com/repos/pandas-d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://github.com/pandas-dev/pandas/pull/33839</td>\n",
       "      <td>608002609</td>\n",
       "      <td>MDExOlB1bGxSZXF1ZXN0NDA5ODY0NjUy</td>\n",
       "      <td>33839</td>\n",
       "      <td>CLN: freq inference in DTI/TDI set ops</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-04-28 03:46:04+00:00</td>\n",
       "      <td>2020-04-28 03:46:04+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>MEMBER</td>\n",
       "      <td>These ops are a PITA for getting the freq chec...</td>\n",
       "      <td>{'url': 'https://api.github.com/repos/pandas-d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://github.com/pandas-dev/pandas/issues/33838</td>\n",
       "      <td>607976037</td>\n",
       "      <td>MDU6SXNzdWU2MDc5NzYwMzc=</td>\n",
       "      <td>33838</td>\n",
       "      <td>API: EA/Index/Series.factorize should have sam...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-04-28 02:28:10+00:00</td>\n",
       "      <td>2020-04-28 02:28:10+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>MEMBER</td>\n",
       "      <td>This will allow pd.factorize to dispatch to th...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://github.com/pandas-dev/pandas/pull/33836</td>\n",
       "      <td>607947698</td>\n",
       "      <td>MDExOlB1bGxSZXF1ZXN0NDA5ODIzMjQ4</td>\n",
       "      <td>33836</td>\n",
       "      <td>BUG: preserve freq in DTI/TDI factorize</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-04-28 00:58:46+00:00</td>\n",
       "      <td>2020-04-28 04:29:45+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>MEMBER</td>\n",
       "      <td>- [ ] closes #xxxx\\r\\n- [x] tests added / pass...</td>\n",
       "      <td>{'url': 'https://api.github.com/repos/pandas-d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "1  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "2  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "3  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "4  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "\n",
       "                                   repository_url  \\\n",
       "0  https://api.github.com/repos/pandas-dev/pandas   \n",
       "1  https://api.github.com/repos/pandas-dev/pandas   \n",
       "2  https://api.github.com/repos/pandas-dev/pandas   \n",
       "3  https://api.github.com/repos/pandas-dev/pandas   \n",
       "4  https://api.github.com/repos/pandas-dev/pandas   \n",
       "\n",
       "                                          labels_url  \\\n",
       "0  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "1  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "2  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "3  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "4  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "\n",
       "                                        comments_url  \\\n",
       "0  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "1  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "2  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "3  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "4  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "\n",
       "                                          events_url  \\\n",
       "0  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "1  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "2  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "3  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "4  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "\n",
       "                                            html_url         id  \\\n",
       "0  https://github.com/pandas-dev/pandas/issues/33841  608107436   \n",
       "1    https://github.com/pandas-dev/pandas/pull/33840  608057209   \n",
       "2    https://github.com/pandas-dev/pandas/pull/33839  608002609   \n",
       "3  https://github.com/pandas-dev/pandas/issues/33838  607976037   \n",
       "4    https://github.com/pandas-dev/pandas/pull/33836  607947698   \n",
       "\n",
       "                            node_id  number  \\\n",
       "0          MDU6SXNzdWU2MDgxMDc0MzY=   33841   \n",
       "1  MDExOlB1bGxSZXF1ZXN0NDA5OTA4NjMy   33840   \n",
       "2  MDExOlB1bGxSZXF1ZXN0NDA5ODY0NjUy   33839   \n",
       "3          MDU6SXNzdWU2MDc5NzYwMzc=   33838   \n",
       "4  MDExOlB1bGxSZXF1ZXN0NDA5ODIzMjQ4   33836   \n",
       "\n",
       "                                               title  ... assignee assignees  \\\n",
       "0  BUG:RecursionError occur when running the scri...  ...      NaN        []   \n",
       "1  DOC: Fix groupby.agg/transform API reference a...  ...      NaN        []   \n",
       "2             CLN: freq inference in DTI/TDI set ops  ...      NaN        []   \n",
       "3  API: EA/Index/Series.factorize should have sam...  ...      NaN        []   \n",
       "4            BUG: preserve freq in DTI/TDI factorize  ...      NaN        []   \n",
       "\n",
       "                                           milestone  comments  \\\n",
       "0                                               None         2   \n",
       "1  {'url': 'https://api.github.com/repos/pandas-d...         1   \n",
       "2                                               None         0   \n",
       "3                                               None         0   \n",
       "4                                               None         2   \n",
       "\n",
       "                 created_at                updated_at closed_at  \\\n",
       "0 2020-04-28 07:59:09+00:00 2020-04-28 08:11:12+00:00       NaT   \n",
       "1 2020-04-28 06:22:51+00:00 2020-04-28 06:25:59+00:00       NaT   \n",
       "2 2020-04-28 03:46:04+00:00 2020-04-28 03:46:04+00:00       NaT   \n",
       "3 2020-04-28 02:28:10+00:00 2020-04-28 02:28:10+00:00       NaT   \n",
       "4 2020-04-28 00:58:46+00:00 2020-04-28 04:29:45+00:00       NaT   \n",
       "\n",
       "   author_association                                               body  \\\n",
       "0                NONE  This is my first issue. So, if I'm wrong, plea...   \n",
       "1              MEMBER  - xref https://github.com/pandas-dev/pandas/pu...   \n",
       "2              MEMBER  These ops are a PITA for getting the freq chec...   \n",
       "3              MEMBER  This will allow pd.factorize to dispatch to th...   \n",
       "4              MEMBER  - [ ] closes #xxxx\\r\\n- [x] tests added / pass...   \n",
       "\n",
       "                                        pull_request  \n",
       "0                                                NaN  \n",
       "1  {'url': 'https://api.github.com/repos/pandas-d...  \n",
       "2  {'url': 'https://api.github.com/repos/pandas-d...  \n",
       "3                                                NaN  \n",
       "4  {'url': 'https://api.github.com/repos/pandas-d...  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_json('https://api.github.com/repos/pydata/pandas/issues?per_page=5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compressed files (Gzip)\n",
    "\n",
    "Another way we save storage and network resources is by using **compression**. Many times data sets will contain patterns that can be used to reduce the amount of space needed to store the information.\n",
    "\n",
    "A simple example is the following list of numbers: 10, 10, 10, 2, 3, 3, 3, 3, 3, 50, 50, 1, 1, 50, 10, 10, 10, 10\n",
    "\n",
    "Rather than writing out the full list of numbers (18 integers), we can represent the same information with only 14 numbers: (3, 10), (1, 2), (5, 3), (2, 50), (2, 1), (1, 50), (4, 10)\n",
    "\n",
    "Here the first number in each pair is the number of repetitions, and the second number in the pair is the actual value. We've successfully reduced the amount of numbers we need to represent the same data. Most forms of compression use a similar idea, although actual implementations are usually more complex.\n",
    "\n",
    "In the world of data science, the most common compression is Gzip (which uses the [deflate algorithm](http://www.infinitepartitions.com/art001.html)). Gzip files end with the extension `.gz`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-04-28 08:28:45--  https://archive.org/stream/TheEpicofGilgamesh_201606/eog_djvu.txt\n",
      "Resolving archive.org (archive.org)... 207.241.224.2\n",
      "Connecting to archive.org (archive.org)|207.241.224.2|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [text/html]\n",
      "Saving to: ‘./data/eog_djvu.txt’\n",
      "\n",
      "eog_djvu.txt            [  <=>               ] 164.85K   764KB/s    in 0.2s    \n",
      "\n",
      "2020-04-28 08:28:46 (764 KB/s) - ‘./data/eog_djvu.txt’ saved [168804]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -P ./data/ https://archive.org/stream/TheEpicofGilgamesh_201606/eog_djvu.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 jovyan users 165K Apr 28 08:28 ./data/eog_djvu.txt\r\n",
      "-rw-r--r-- 1 jovyan users  47K Apr 28 08:31 ./data/eog_djvu.txt.gz\r\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "\n",
    "with open('./data/eog_djvu.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "with gzip.open('./data/eog_djvu.txt.gz', 'wb') as f:\n",
    "    f.write(text.encode('utf-8'))\n",
    "\n",
    "!ls -lh ./data/eog*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were able to compress the text of The Epic of Gilgamesh to a third of its original size! Remember that compression depends on patterns in the data. Language has a lot of patterns, but what would happen if we scrambled all the letters in the text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 jovyan users 165K Apr 28 08:28 ./data/eog_djvu.txt\r\n",
      "-rw-r--r-- 1 jovyan users  47K Apr 28 08:31 ./data/eog_djvu.txt.gz\r\n",
      "-rw-r--r-- 1 jovyan users 140K Apr 28 08:32 ./data/eog_djvu_scrambled.txt.gz\r\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "with gzip.open('./data/eog_djvu_scrambled.txt.gz', 'wb') as f:\n",
    "    f.write(np.random.permutation(list(text)))\n",
    "\n",
    "!ls -lh ./data/eog*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scrambled version only compressed to two-thirds the size of the original. Compression won't perform very well on random data. Compression also doesn't work very well on data that is already small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 jovyan users  5 Apr 28 08:34 ./data/short_text.txt\r\n",
      "-rw-r--r-- 1 jovyan users 40 Apr 28 08:34 ./data/short_text.txt.gz\r\n"
     ]
    }
   ],
   "source": [
    "short_text = 'Hello'\n",
    "\n",
    "with open('./data/short_text.txt', 'w') as f:\n",
    "    f.write(short_text)\n",
    "\n",
    "with gzip.open('./data/short_text.txt.gz', 'wb') as f:\n",
    "    f.write(short_text.encode('utf-8'))\n",
    "\n",
    "!ls -lh ./data/short_text*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The compressed file is bigger than the plain text! That's because the compressed file includes a header, which takes up a small amount of extra space. Also, since the text is so short, it's not possible to use patterns to represent the text more efficiently. Therefore we usually save compression for large files.\n",
    "\n",
    "You may have noticed that when we write Gzip files, we have been using a `'wb'` flag instead of a plain `'w'` flag. This is because Gzip is not plain text. When compressing the file we write _binary_ files. The files are not readable as plain text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001f�\b\bz�^\u0002�short_text.txt\u0000�H���\u0007\u0000����\u0005\u0000\u0000\u0000"
     ]
    }
   ],
   "source": [
    "# we have to uncompress the file\n",
    "# before we can read it\n",
    "\n",
    "!cat ./data/short_text.txt.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should only use `'w'` for plain text files (which includes CSV and JSON). Using `'w'` instead of `'wb'` for Gzip files, or other files which are not plain text (e.g. images), could damage the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serialization (`pickle`)\n",
    "\n",
    "Often we will want to save our work in Python and come back to it later. However, that work might be a machine learning model or some other complex object in Python. How do we save complex Python objects? Python has a module for this purpose called `pickle`. We can use `pickle` to write a binary file that contains all the information about a Python object. Later we can load that pickle file and reconstruct the object in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_example = ['hello', {'a': 23, 'b': True}, (1, 2, 3), [['dogs', 'cats'], None]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\n",
      "\u001b[0;32m<ipython-input-72-dc175613edd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m      2\u001b[0m \u001b[0;31m# we can't save this as text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/pickle_example.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_example\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: write() argument must be str, not list\n"
     ]
    }
   ],
   "source": [
    "%%expect_exception TypeError\n",
    "\n",
    "# we can't save this as text\n",
    "with open('./data/pickle_example.txt', 'w') as f:\n",
    "    f.write(pickle_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', {'a': 23, 'b': True}, (1, 2, 3), [['dogs', 'cats'], None]]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# we can save it as a pickle\n",
    "with open('./data/pickle_example.pkl', 'wb') as f:\n",
    "    pickle.dump(pickle_example, f)\n",
    "\n",
    "with open('./data/pickle_example.pkl', 'rb') as f:\n",
    "    reloaded_example = pickle.load(f)\n",
    "\n",
    "reloaded_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/pickle_example.json','w')  as f:\n",
    "    json.dump(pickle_example,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', {'a': 23, 'b': True}, [1, 2, 3], [['dogs', 'cats'], None]]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./data/pickle_example.json','r')  as f:\n",
    "    pickle_json=json.load(f)\n",
    "\n",
    "pickle_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the reloaded example is the same as the original\n",
    "\n",
    "reloaded_example == pickle_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_json == pickle_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickle is an important tool for data scientists. Data processing and training machine learning models can take a long time, and it is useful to save checkpoints.\n",
    "\n",
    "Pandas also has `to_pickle` and `read_pickle` methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy file formats\n",
    "\n",
    "NumPy also has methods for saving and loading data. They are straightforward to use. You may encounter these when working with certain machine learning libraries that require data be stored in NumPy arrays. NumPy arrays are also often used when working with image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.38676539 0.77165934 0.16195625 0.40671809]\n",
      " [0.11053533 0.37554917 0.11194558 0.91217863]\n",
      " [0.72582912 0.20122602 0.524241   0.55652904]\n",
      " [0.75437236 0.65067645 0.23848911 0.49162626]]\n"
     ]
    }
   ],
   "source": [
    "sample_array = np.random.random((4, 4))\n",
    "print(sample_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save as plain text\n",
    "np.savetxt('./data/sample_array.txt', sample_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.867653918591015261e-01 7.716593435062923945e-01 1.619562491305795993e-01 4.067180887234541631e-01\r\n",
      "1.105353317555928250e-01 3.755491709534632960e-01 1.119455821574034671e-01 9.121786316528880389e-01\r\n",
      "7.258291169832410406e-01 2.012260237038652200e-01 5.242410002355174514e-01 5.565290409804530825e-01\r\n",
      "7.543723623819048596e-01 6.506764540334181168e-01 2.384891105815407641e-01 4.916262642949347228e-01\r\n"
     ]
    }
   ],
   "source": [
    "!cat ./data/sample_array.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.38676539 0.77165934 0.16195625 0.40671809]\n",
      " [0.11053533 0.37554917 0.11194558 0.91217863]\n",
      " [0.72582912 0.20122602 0.524241   0.55652904]\n",
      " [0.75437236 0.65067645 0.23848911 0.49162626]]\n"
     ]
    }
   ],
   "source": [
    "print(np.loadtxt('./data/sample_array.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save as compressed binary\n",
    "np.save('./data/sample_array.npy', sample_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "�NUMPY\u0001\u0000v\u0000{'descr': '<f8', 'fortran_order': False, 'shape': (4, 4), }                                                          \r\n",
      "\u0016�P����?8e��n��?�\u0007�|���?2�pN�\u0007�? Z�\"\u000b",
      "L�?\u0010>�c�\b�?�7L6w��?���=�0�?�����9�?��t;���?�{�\u000f���?\u0018!��\u0015��?'�-��#�?�9KmW��? .3�φ�?�\u0016�\u0001�v�?"
     ]
    }
   ],
   "source": [
    "!cat ./data/sample_array.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.38676539 0.77165934 0.16195625 0.40671809]\n",
      " [0.11053533 0.37554917 0.11194558 0.91217863]\n",
      " [0.72582912 0.20122602 0.524241   0.55652904]\n",
      " [0.75437236 0.65067645 0.23848911 0.49162626]]\n"
     ]
    }
   ],
   "source": [
    "print(np.load('./data/sample_array.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getnewargs__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__mod__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rmod__',\n",
       " '__rmul__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'capitalize',\n",
       " 'casefold',\n",
       " 'center',\n",
       " 'count',\n",
       " 'encode',\n",
       " 'endswith',\n",
       " 'expandtabs',\n",
       " 'find',\n",
       " 'format',\n",
       " 'format_map',\n",
       " 'index',\n",
       " 'isalnum',\n",
       " 'isalpha',\n",
       " 'isascii',\n",
       " 'isdecimal',\n",
       " 'isdigit',\n",
       " 'isidentifier',\n",
       " 'islower',\n",
       " 'isnumeric',\n",
       " 'isprintable',\n",
       " 'isspace',\n",
       " 'istitle',\n",
       " 'isupper',\n",
       " 'join',\n",
       " 'ljust',\n",
       " 'lower',\n",
       " 'lstrip',\n",
       " 'maketrans',\n",
       " 'partition',\n",
       " 'replace',\n",
       " 'rfind',\n",
       " 'rindex',\n",
       " 'rjust',\n",
       " 'rpartition',\n",
       " 'rsplit',\n",
       " 'rstrip',\n",
       " 'split',\n",
       " 'splitlines',\n",
       " 'startswith',\n",
       " 'strip',\n",
       " 'swapcase',\n",
       " 'title',\n",
       " 'translate',\n",
       " 'upper',\n",
       " 'zfill']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics used by not discussed:\n",
    "- BASH commands (!)\n",
    "- `wget`\n",
    "- `str.split()`\n",
    "- APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Copyright &copy; 2020 The Data Incubator.  All rights reserved.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nbclean": true
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
